{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BCC-BreakHis Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1hbdaBMY03_uEjwE1XeBDP6XWM18w2etR",
      "authorship_tag": "ABX9TyNT23OYg+RX4j/rO452rZmM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D4N18L/Tumor_Detector_CNN_Model/blob/main/BCC_BreakHis_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E79E0CrjsapX"
      },
      "source": [
        " pip install tensorflow-gpu==2.4-rc0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hCWJHVPxoD1",
        "outputId": "c83662ec-830b-4b42-e7a4-5309c66d2e1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puFXqNGbm06q"
      },
      "source": [
        "Import Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c19_s6Xioarj"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten , BatchNormalization\n",
        "from keras.utils import np_utils , to_categorical\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNfrwAo2nBN3"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CMh7IIVmvmX"
      },
      "source": [
        "loadata = pd.read_csv(\"/content/gdrive/MyDrive/Folds.csv\")\n",
        "loadata = loadata.sample(frac=1)\n",
        "loadata.head()\n",
        "path = \"../content/gdrive/MyDrive/BreaKHis_v1/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_dQQXTBnJ0N"
      },
      "source": [
        "Catgorize and Split Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz1xWVHL8C92",
        "outputId": "1a17c092-0142-43e4-8222-d1ef4ddb5fe8"
      },
      "source": [
        "\n",
        "load_dataset = []\n",
        "labels = []\n",
        "\n",
        "for i in tqdm(range(loadata.shape[0])):\n",
        "    img = image.load_img(path + loadata['filename'].iloc[i], target_size=(28,28,1), grayscale=False)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    load_dataset.append(img)\n",
        "    \n",
        "    if (loadata['filename'].iloc[i].find('benign') != -1): \n",
        "        labels.append(0) \n",
        "    else:\n",
        "        labels.append(1)\n",
        "        \n",
        "X = np.array(load_dataset)\n",
        "y = np.array(labels)\n",
        "\n",
        " \n",
        "#Splitting the data in train, test  and validation splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, random_state=42, test_size=0.2 , shuffle=True)\n",
        "\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 2)\n",
        "Y_test = np_utils.to_categorical(y_test, 2)\n",
        "Y_val = np_utils.to_categorical(y_val, 2)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 39545/39545 [2:13:36<00:00,  4.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(31636, 28, 28, 3)\n",
            "(6327, 28, 28, 3)\n",
            "(1582, 28, 28, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OuGkmNAzAFq"
      },
      "source": [
        "#Initialization\n",
        "numepochs = 5\n",
        "numfilter = 30\n",
        "kernel = 4\n",
        "mpool_size = 1\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(numfilter,kernel_size = (3,3),strides=(1,1), padding='valid', activation=ac_function, input_shape=(28,28,3)))\n",
        "  model.add(MaxPool2D(pool_size=mpool_size))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(numfilter,kernel_size = (3,3),strides=(1,1), padding='valid', activation=ac_function))\n",
        "  model.add(MaxPool2D(pool_size=mpool_size))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(numfilter,kernel_size = (3,3),strides=(1,1), padding='valid', activation=ac_function))\n",
        "  model.add(MaxPool2D(pool_size=mpool_size))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(150, activation=ac_function))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(2,activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8RAJ8wknll4"
      },
      "source": [
        "Generate Summary of the archictectire built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euPoWSmxTMGT"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QW8DRH5nrRE"
      },
      "source": [
        "Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYBELpiTTHBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e62003-04b3-4b19-a743-937827b6d553"
      },
      "source": [
        "model.compile(optimizer='adam',loss ='binary_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train,epochs=numepochs, batch_size=200,validation_data=(X_test,Y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "159/159 [==============================] - 189s 1s/step - loss: 0.6360 - accuracy: 0.7767 - val_loss: 0.6283 - val_accuracy: 0.6883\n",
            "Epoch 2/5\n",
            "159/159 [==============================] - 185s 1s/step - loss: 0.5649 - accuracy: 0.8031 - val_loss: 0.6205 - val_accuracy: 0.6883\n",
            "Epoch 3/5\n",
            "159/159 [==============================] - 188s 1s/step - loss: 0.5233 - accuracy: 0.8123 - val_loss: 0.6265 - val_accuracy: 0.6883\n",
            "Epoch 4/5\n",
            "159/159 [==============================] - 184s 1s/step - loss: 0.5017 - accuracy: 0.8097 - val_loss: 0.5389 - val_accuracy: 0.7637\n",
            "Epoch 5/5\n",
            "159/159 [==============================] - 184s 1s/step - loss: 0.4883 - accuracy: 0.8085 - val_loss: 0.5152 - val_accuracy: 0.7700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z__G6ui6lDb6"
      },
      "source": [
        "# **Initialize Model Name **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAwRKix3lCP2"
      },
      "source": [
        "Modelname = \"BCC_BreakHis.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6Rz20wUmYlo"
      },
      "source": [
        "# **Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGnWcX8OmYlp"
      },
      "source": [
        "model.save(Modelname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p51EsyAKmYlp"
      },
      "source": [
        "# **Test Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4i0xAcumYlq",
        "outputId": "ac0ce302-4ac3-4f14-c404-092225caaf14"
      },
      "source": [
        "Test_loss,Test_accuaracy = model.evaluate(X_test,Y_test,verbose=1)\n",
        "print(\"\" , Test_accuaracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "198/198 [==============================] - 7s 37ms/step - loss: 0.1539 - accuracy: 0.9551\n",
            " 0.9551129937171936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VP9IzcfmYlq"
      },
      "source": [
        "# **Convert TensorFlow Model into TFLITE **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHn4cDrFd5QW",
        "outputId": "c72b9233-aa4f-4c0e-954d-39123ffc0636"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1397: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmprtl3x3w3/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmNt913GIew1"
      },
      "source": [
        "# **SAVE TFLITE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLevgHgHIjFD"
      },
      "source": [
        "with open('CNN_BreakHis.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV3-yR2oWI16"
      },
      "source": [
        "labels = ['benign', 'malignant']\n",
        "\n",
        "with open('labels.txt', w) as f:\n",
        "  f.write('\\n'.join(labels))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}